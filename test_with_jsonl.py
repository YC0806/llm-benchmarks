#!/usr/bin/env python3
"""
ä½¿ç”¨ online_query_etl_100.jsonl æµ‹è¯•å¤§æ¨¡å‹ API çš„ä¾¿æ·è„šæœ¬

ç”¨æ³•:
    python test_with_jsonl.py --help
    python test_with_jsonl.py --model gpt-4 --num-prompts 10
"""

import argparse
import json
import os
import subprocess
import sys


def count_jsonl_lines(file_path):
    """ç»Ÿè®¡ JSONL æ–‡ä»¶çš„è¡Œæ•°"""
    with open(file_path, 'r') as f:
        return sum(1 for _ in f)


def validate_jsonl(file_path, num_lines=3):
    """éªŒè¯ JSONL æ–‡ä»¶æ ¼å¼"""
    try:
        with open(file_path, 'r') as f:
            for i, line in enumerate(f):
                if i >= num_lines:
                    break
                json.loads(line)
        return True
    except json.JSONDecodeError as e:
        print(f"âŒ JSONL æ ¼å¼é”™è¯¯: {e}")
        return False
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ online_query_etl_100.jsonl æµ‹è¯•å¤§æ¨¡å‹ API",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºç¡€æµ‹è¯•ï¼ˆ10æ¡æ•°æ®ï¼‰
  python test_with_jsonl.py --model gpt-4

  # æµ‹è¯•50æ¡ï¼Œè¯·æ±‚é€Ÿç‡5 RPS
  python test_with_jsonl.py --model gpt-4 --num-prompts 50 --request-rate 5

  # ä½¿ç”¨å®Œæ•´ API URLï¼ˆè‡ªåŠ¨è§£æ base-url å’Œ endpointï¼‰
  python test_with_jsonl.py \\
      --model deepseek-chat \\
      --api-url https://api.deepseek.com/v1/chat/completions \\
      --num-prompts 20

  # ä½¿ç”¨åŸºç¡€ URLï¼ˆä½¿ç”¨é»˜è®¤ endpointï¼‰
  python test_with_jsonl.py \\
      --model Qwen/Qwen2.5-7B-Instruct \\
      --api-url http://localhost:8000 \\
      --backend vllm \\
      --num-prompts 20

  # ä¿å­˜ç»“æœå¹¶æŒ‡å®šè¾“å‡ºç›®å½•
  python test_with_jsonl.py \\
      --model gpt-4 \\
      --num-prompts 100 \\
      --save-result \\
      --result-dir ./my_results

æ”¯æŒçš„åç«¯ç±»å‹:
  - openai-chat: OpenAI Chat Completions API
  - openai: OpenAI Completions API
  - vllm: vLLM OpenAI å…¼å®¹æœåŠ¡å™¨
  - tgi: HuggingFace TGI
  - lmdeploy: LMDeploy
  - sglang: SGLang
  - tensorrt-llm: TensorRT-LLM
        """
    )

    # å¿…éœ€å‚æ•°
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-4",
        help="æ¨¡å‹åç§° (é»˜è®¤: gpt-4)"
    )

    # API é…ç½®
    parser.add_argument(
        "--api-url",
        type=str,
        default="https://api.openai.com",
        help="API URL (å¯ä»¥æ˜¯åŸºç¡€ URL æˆ–å®Œæ•´ URLï¼Œé»˜è®¤: https://api.openai.com)"
    )
    parser.add_argument(
        "--base-url",
        type=str,
        default=None,
        help="[å·²å¼ƒç”¨] ä½¿ç”¨ --api-url ä»£æ›¿"
    )
    parser.add_argument(
        "--backend",
        type=str,
        default="openai-chat",
        choices=["openai-chat", "openai", "vllm", "tgi", "lmdeploy",
                 "sglang", "tensorrt-llm", "llama.cpp", "deepspeed-mii"],
        help="åç«¯ç±»å‹ (é»˜è®¤: openai-chat)"
    )

    # æ•°æ®é›†é…ç½®
    parser.add_argument(
        "--dataset-path",
        type=str,
        default="online_query_etl_100.jsonl",
        help="JSONL æ•°æ®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: online_query_etl_100.jsonl)"
    )
    parser.add_argument(
        "--num-prompts",
        type=int,
        default=10,
        help="æµ‹è¯•çš„å¯¹è¯æ•°é‡ (é»˜è®¤: 10)"
    )

    # æ€§èƒ½å‚æ•°
    parser.add_argument(
        "--request-rate",
        type=float,
        default=1.0,
        help="è¯·æ±‚é€Ÿç‡ (RPS, é»˜è®¤: 1.0)"
    )
    parser.add_argument(
        "--max-concurrency",
        type=int,
        default=None,
        help="æœ€å¤§å¹¶å‘è¯·æ±‚æ•°"
    )

    # è¾“å‡ºé…ç½®
    parser.add_argument(
        "--save-result",
        action="store_true",
        help="ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"
    )
    parser.add_argument(
        "--result-dir",
        type=str,
        default="./results",
        help="ç»“æœä¿å­˜ç›®å½• (é»˜è®¤: ./results)"
    )
    parser.add_argument(
        "--result-filename",
        type=str,
        default=None,
        help="ç»“æœæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰"
    )

    # å…¶ä»–é€‰é¡¹
    parser.add_argument(
        "--disable-tqdm",
        action="store_true",
        help="ç¦ç”¨è¿›åº¦æ¡"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="è¯¦ç»†è¾“å‡º"
    )

    args = parser.parse_args()

    # å¤„ç† base-url çš„å‘åå…¼å®¹
    if args.base_url:
        print("âš ï¸  è­¦å‘Š: --base-url å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ --api-url")
        args.api_url = args.base_url

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists(args.dataset_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ '{args.dataset_path}'")
        sys.exit(1)

    print("=" * 50)
    print("  LLM API æµ‹è¯•")
    print("=" * 50)
    print()

    # éªŒè¯ JSONL æ ¼å¼
    print("ğŸ“ éªŒè¯æ•°æ®æ–‡ä»¶æ ¼å¼...")
    if not validate_jsonl(args.dataset_path):
        sys.exit(1)

    # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
    total_lines = count_jsonl_lines(args.dataset_path)
    print(f"âœ“ æ•°æ®æ–‡ä»¶æ ¼å¼æ­£ç¡®")
    print()

    # æ˜¾ç¤ºé…ç½®
    print("ğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"  æ•°æ®æ–‡ä»¶: {args.dataset_path}")
    print(f"  æ€»å¯¹è¯æ•°: {total_lines}")
    print(f"  æµ‹è¯•æ•°é‡: {args.num_prompts}")
    print(f"  æ¨¡å‹: {args.model}")
    print(f"  APIåœ°å€: {args.api_url}")
    print(f"  åç«¯ç±»å‹: {args.backend}")
    print(f"  è¯·æ±‚é€Ÿç‡: {args.request_rate} RPS")
    if args.max_concurrency:
        print(f"  æœ€å¤§å¹¶å‘: {args.max_concurrency}")
    if args.save_result:
        print(f"  ç»“æœä¿å­˜: {args.result_dir}")
    print()

    # æ£€æŸ¥æ•°é‡
    if args.num_prompts > total_lines:
        print(f"âš ï¸  è­¦å‘Š: è¯·æ±‚æ•°é‡({args.num_prompts})è¶…è¿‡æ–‡ä»¶è¡Œæ•°({total_lines})")
        args.num_prompts = total_lines
        print(f"  å·²è°ƒæ•´ä¸º: {args.num_prompts}")
        print()

    # æ£€æŸ¥ API Keyï¼ˆå¦‚æœæ˜¯ OpenAIï¼‰
    if "openai" in args.backend and not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  è­¦å‘Š: OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        print("è¯·å…ˆè®¾ç½®: export OPENAI_API_KEY='your-api-key'")
        print()
        response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            sys.exit(0)
        print()

    # è§£æ API URL ä¸º base-url å’Œ endpoint
    # æ”¯æŒè¾“å…¥å®Œæ•´ URL (å¦‚ https://api.openai.com/v1/chat/completions)
    # æˆ–åŸºç¡€ URL (å¦‚ https://api.openai.com)
    from urllib.parse import urlparse

    parsed_url = urlparse(args.api_url)
    base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
    endpoint = parsed_url.path if parsed_url.path else None

    # å¦‚æœç”¨æˆ·æä¾›äº†å®Œæ•´çš„ endpoint è·¯å¾„ï¼Œä½¿ç”¨å®ƒ
    # å¦åˆ™è®© benchmark_serving.py ä½¿ç”¨é»˜è®¤ endpoint

    # æ„å»ºå‘½ä»¤
    cmd = [
        "python", "benchmark_serving.py",
        "--backend", args.backend,
        "--model", args.model,
        "--base-url", base_url,
        "--dataset-name", "custom",
        "--dataset-path", args.dataset_path,
        "--num-prompts", str(args.num_prompts),
        "--request-rate", str(args.request_rate),
    ]

    # å¦‚æœæä¾›äº†éé»˜è®¤çš„ endpointï¼Œæ·»åŠ å®ƒ
    if endpoint and endpoint not in ['', '/']:
        cmd.extend(["--endpoint", endpoint])

    if args.max_concurrency:
        cmd.extend(["--max-concurrency", str(args.max_concurrency)])

    if args.save_result:
        cmd.append("--save-result")
        cmd.extend(["--result-dir", args.result_dir])
        if args.result_filename:
            cmd.extend(["--result-filename", args.result_filename])

    if args.disable_tqdm:
        cmd.append("--disable-tqdm")

    print("=" * 50)
    print("  ğŸš€ å¼€å§‹æµ‹è¯•...")
    print("=" * 50)
    print()

    if args.verbose:
        print("æ‰§è¡Œå‘½ä»¤:")
        print(" ".join(cmd))
        print()

    # æ‰§è¡Œæµ‹è¯•
    try:
        result = subprocess.run(cmd, check=True)
        print()
        print("=" * 50)
        print("  âœ… æµ‹è¯•å®Œæˆï¼")
        print("=" * 50)

        if args.save_result:
            print()
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ° {args.result_dir}/ ç›®å½•")
            print()
            print("æŸ¥çœ‹ç»“æœ:")
            print(f"  ls -lt {args.result_dir}/*.json | head -1")

    except subprocess.CalledProcessError as e:
        print()
        print("=" * 50)
        print("  âŒ æµ‹è¯•å¤±è´¥")
        print("=" * 50)
        sys.exit(e.returncode)
    except KeyboardInterrupt:
        print()
        print()
        print("âš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)


if __name__ == "__main__":
    main()
