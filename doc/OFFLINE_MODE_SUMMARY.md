# ç¦»çº¿æ¨¡å¼æ”¹é€ æ€»ç»“

## ğŸ“‹ é¡¹ç›®ç›®æ ‡

å°† LLM åŸºå‡†æµ‹è¯•å·¥å…·æ”¹é€ ä¸ºæ”¯æŒ**ç¦»çº¿/å†…ç½‘ç¯å¢ƒ**ï¼Œç§»é™¤æ‰€æœ‰éœ€è¦å¤–éƒ¨ç½‘ç»œè®¿é—®çš„ä¾èµ–ã€‚

## âœ… å®Œæˆçš„æ”¹é€ 

### 1. ä¾èµ–ç²¾ç®€

**ä» â†’ åˆ°**ï¼š
- **10+ ä¸ªä¾èµ–** â†’ **4 ä¸ªæ ¸å¿ƒä¾èµ–**
- **~2GB å®‰è£…å¤§å°** â†’ **~50MB**
- **~5s å¯åŠ¨æ—¶é—´** â†’ **~1s**
- **~1GB å†…å­˜å ç”¨** â†’ **~100MB**

**æ ¸å¿ƒä¾èµ–åˆ—è¡¨**ï¼š
```txt
numpy>=1.24
pandas>=2.0.0
aiohttp>=3.10
tqdm>=4.66
```

### 2. ç§»é™¤çš„ä¾èµ–

#### å®Œå…¨ç§»é™¤ï¼ˆæ— æ³•é€‰è£…ï¼‰ï¼š
1. **transformers** - tokenizer ä¾èµ–
   - éœ€è¦ä¸‹è½½æ¨¡å‹è¯è¡¨
   - éœ€è¦è®¿é—® HuggingFace
   - å·²æ”¹ç”¨å­—ç¬¦ä¼°ç®— + API token ç»Ÿè®¡

2. **huggingface_hub** - HuggingFace é›†æˆ
   - éœ€è¦å¤–éƒ¨ç½‘ç»œè®¿é—®
   - ç”¨äºä¸‹è½½æ•°æ®é›†å’Œæ¨¡å‹

3. **datasets** - HuggingFace æ•°æ®é›†åº“
   - éœ€è¦ä»äº’è”ç½‘ä¸‹è½½æ•°æ®é›†

#### æ”¹ä¸ºå¯é€‰ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰ï¼š
4. **xlsxwriter** - Excel å¯¼å‡º
   - å·²æä¾› CSV å¯¼å‡ºä½œä¸ºæ›¿ä»£

5. **Pillow** - å›¾åƒå¤„ç†
   - å¤šæ¨¡æ€åŠŸèƒ½åœ¨ç¦»çº¿æ¨¡å¼ä¸‹ç¦ç”¨

6. **soundfile, librosa** - éŸ³é¢‘å¤„ç†
   - éŸ³é¢‘åŠŸèƒ½åœ¨ç¦»çº¿æ¨¡å¼ä¸‹ç¦ç”¨

### 3. ä»£ç æ”¹é€ 

#### [backend_request_func.py](backend_request_func.py)

**ç§»é™¤**ï¼š
```python
# å®Œå…¨ç§»é™¤
from transformers import ...
from huggingface_hub.constants import ...

def get_tokenizer(...): ...
def get_model(...): ...
```

**ä¿ç•™**ï¼š
```python
def estimate_token_count(text: str) -> int:
    """
    åŸºäºå­—ç¬¦æ•°ä¼°ç®— token æ•°é‡
    - ä¸­æ–‡/CJK: ~1.5 å­—ç¬¦/token
    - è‹±æ–‡: ~4 å­—ç¬¦/token
    """
    ...
```

#### [benchmark_serving.py](benchmark_serving.py)

**ç§»é™¤**ï¼š
- æ‰€æœ‰ `tokenizer` å‚æ•°
- `get_tokenizer()` è°ƒç”¨
- tokenizer åˆå§‹åŒ–ä»£ç 
- tokenizer è­¦å‘Šä¿¡æ¯

**æ›´æ–°**ï¼š
```python
# å‡½æ•°ç­¾åç§»é™¤ tokenizer å‚æ•°
def calculate_metrics(...):  # NO tokenizer
def benchmark(...):  # NO tokenizer
```

**ç¦ç”¨æ•°æ®é›†**ï¼š
- âŒ HuggingFace æ•°æ®é›† (hf)
- âŒ ShareGPT
- âŒ BurstGPT
- âŒ Random
- âŒ Sonnetï¼ˆé openai-chat åç«¯ï¼‰

**ä¿ç•™æ•°æ®é›†**ï¼š
- âœ… Customï¼ˆæœ¬åœ° JSONLï¼‰
- âœ… Sonnetï¼ˆä»… openai-chatï¼‰

#### [benchmark_dataset.py](benchmark_dataset.py)

**ç§»é™¤**ï¼š
```python
# å®Œå…¨ç§»é™¤
try:
    from transformers import PreTrainedTokenizerBase
    ...
except ImportError:
    ...
```

**æ›¿æ¢**ï¼š
```python
# æ‰€æœ‰ PreTrainedTokenizerBase æ›¿æ¢ä¸º Any
def sample(self, tokenizer: Any, ...): ...
```

### 4. æ–°å¢åŠŸèƒ½

#### æµ‹è¯•å·¥å…·

1. **[test_with_jsonl.py](test_with_jsonl.py)**
   - ä¾¿æ·çš„ Python æµ‹è¯•è„šæœ¬
   - æ”¯æŒæ‰€æœ‰é…ç½®é€‰é¡¹
   - è‡ªåŠ¨éªŒè¯ JSONL æ ¼å¼

2. **[test_with_jsonl.sh](test_with_jsonl.sh)**
   - äº¤äº’å¼ Shell è„šæœ¬
   - é€‚åˆå¿«é€Ÿæµ‹è¯•

3. **[inspect_jsonl.py](inspect_jsonl.py)**
   - JSONL æ•°æ®åˆ†æå·¥å…·
   - æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å’Œç¤ºä¾‹

#### æ–‡æ¡£

1. **[JSONL_TESTING_GUIDE.md](JSONL_TESTING_GUIDE.md)**
   - å®Œæ•´çš„ JSONL æµ‹è¯•æŒ‡å—
   - åŒ…å«ç¤ºä¾‹å’Œæœ€ä½³å®è·µ

2. **[TOKENIZER_REMOVED.md](TOKENIZER_REMOVED.md)**
   - Tokenizer ç§»é™¤è¯´æ˜
   - è¯¯å·®åˆ†æå’Œæƒè¡¡

3. **[VLLM_DEPENDENCY_REMOVAL.md](VLLM_DEPENDENCY_REMOVAL.md)**
   - vLLM ä¾èµ–ç§»é™¤è¯´æ˜

4. **[XLSXWRITER_OPTIONAL.md](XLSXWRITER_OPTIONAL.md)**
   - xlsxwriter å¯é€‰è¯´æ˜

5. **[OFFLINE_MODE_SUMMARY.md](OFFLINE_MODE_SUMMARY.md)** (æœ¬æ–‡ä»¶)
   - å®Œæ•´æ”¹é€ æ€»ç»“

---

## ğŸ¯ Token è®¡æ•°ç­–ç•¥

### æ–°æ–¹æ¡ˆ

```
1. API å“åº” token ç»Ÿè®¡ï¼ˆæœ€å‡†ç¡®ï¼‰
   â†“ å¦‚æœä¸å¯ç”¨
2. å­—ç¬¦æ•°ä¼°ç®—ï¼ˆè¿‘ä¼¼ï¼ŒÂ±10-20% è¯¯å·®ï¼‰
```

### ä¼°ç®—å…¬å¼

```python
def estimate_token_count(text: str) -> int:
    cjk_count = count_cjk_characters(text)
    non_cjk_count = len(text) - cjk_count

    cjk_tokens = cjk_count / 1.5      # ä¸­æ–‡ ~1.5 å­—ç¬¦/token
    non_cjk_tokens = non_cjk_count / 4.0  # è‹±æ–‡ ~4 å­—ç¬¦/token

    return max(1, int(cjk_tokens + non_cjk_tokens))
```

### Token ç»Ÿè®¡æ¥æº

| Token ç±»å‹ | æ•°æ®æ¥æº | ç²¾åº¦ |
|-----------|---------|------|
| **Input tokens** | å­—ç¬¦ä¼°ç®— | Â±10-20% |
| **Output tokens** | API å“åº”ï¼ˆå¤§å¤šæ•°ï¼‰ | ç²¾ç¡® |
| **Output tokens** | å­—ç¬¦ä¼°ç®—ï¼ˆå°‘æ•°ï¼‰ | Â±10-20% |

### æ”¯æŒ API

| API | Input Token | Output Token | è¯´æ˜ |
|-----|-------------|--------------|------|
| OpenAI | API è¿”å› | API è¿”å› | ç²¾ç¡® |
| vLLM | API è¿”å› | API è¿”å› | ç²¾ç¡® |
| LMDeploy | API è¿”å› | API è¿”å› | ç²¾ç¡® |
| SGLang | API è¿”å› | API è¿”å› | ç²¾ç¡® |
| TGI | ä¼°ç®— | API è¿”å› | Input è¿‘ä¼¼ |
| TensorRT-LLM | ä¼°ç®— | ä¼°ç®—/API | å–å†³äºå®ç° |

---

## ğŸ“Š æ•°æ®é›†æ”¯æŒ

### æ”¯æŒçš„æ•°æ®é›†

#### 1. Customï¼ˆæ¨èï¼‰

**æ ¼å¼**ï¼šJSONLï¼Œæ¯è¡Œä¸€ä¸ª JSON æ•°ç»„

```json
[
  {"role": "user", "content": "é—®é¢˜"},
  {"role": "assistant", "content": "å›ç­”"}
]
```

**ä½¿ç”¨**ï¼š
```bash
python benchmark_serving.py \
    --dataset-name custom \
    --dataset-path your_data.jsonl \
    ...
```

**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨ç¦»çº¿
- âœ… çµæ´»è‡ªå®šä¹‰
- âœ… æ”¯æŒå¤šè½®å¯¹è¯

#### 2. Sonnet

**é™åˆ¶**ï¼šä»…æ”¯æŒ `openai-chat` åç«¯

**ä½¿ç”¨**ï¼š
```bash
python benchmark_serving.py \
    --dataset-name sonnet \
    --backend openai-chat \
    ...
```

### ç¦ç”¨çš„æ•°æ®é›†

ä»¥ä¸‹æ•°æ®é›†éœ€è¦å¤–éƒ¨ä¸‹è½½ï¼Œå·²åœ¨ç¦»çº¿æ¨¡å¼ç¦ç”¨ï¼š

- âŒ `hf` - HuggingFace æ•°æ®é›†
- âŒ `sharegpt` - ShareGPT æ•°æ®é›†
- âŒ `burstgpt` - BurstGPT æ•°æ®é›†
- âŒ `random` - éšæœºåˆæˆæ•°æ®é›†

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ `custom` æ•°æ®é›† + æœ¬åœ° JSONL æ–‡ä»¶

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install numpy pandas aiohttp tqdm
```

### 2. å‡†å¤‡æ•°æ®

ä½¿ç”¨é¡¹ç›®è‡ªå¸¦çš„ç¤ºä¾‹æ•°æ®ï¼š
```bash
ls online_query_etl_100.jsonl
```

æˆ–åˆ›å»ºè‡ªå·±çš„ JSONL æ–‡ä»¶ï¼š
```json
[{"role": "user", "content": "ä½ å¥½"}, {"role": "assistant", "content": "ä½ å¥½ï¼"}]
[{"role": "user", "content": "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"}, {"role": "assistant", "content": "..."}]
```

### 3. è¿è¡Œæµ‹è¯•

#### æ–¹æ³• 1ï¼šä½¿ç”¨ä¾¿æ·è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 10 \
    --request-rate 1
```

#### æ–¹æ³• 2ï¼šç›´æ¥ä½¿ç”¨ benchmark_serving.py

```bash
python benchmark_serving.py \
    --backend openai-chat \
    --model gpt-4 \
    --base-url https://api.openai.com \
    --dataset-name custom \
    --dataset-path online_query_etl_100.jsonl \
    --num-prompts 10 \
    --request-rate 1
```

### 4. æŸ¥çœ‹ç»“æœ

```bash
# å®æ—¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
==================== Serving Benchmark Result ====================
Successful requests:                     10
Benchmark duration (s):                  12.34
Total input tokens:                      1523
Total generated tokens:                  4568
Request throughput (req/s):              0.81
Input token throughput (tok/s):          123.45
Output token throughput (tok/s):         370.12
...
```

---

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: å†…ç½‘ç¯å¢ƒæµ‹è¯•

```bash
# æµ‹è¯•å†…ç½‘éƒ¨ç½²çš„å¤§æ¨¡å‹ API
python test_with_jsonl.py \
    --model qwen-72b \
    --base-url http://10.0.0.100:8000 \
    --backend vllm \
    --num-prompts 100 \
    --request-rate 10 \
    --save-result
```

**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨ç¦»çº¿è¿è¡Œ
- âœ… æ— éœ€å¤–éƒ¨ä¾èµ–
- âœ… å¿«é€Ÿéƒ¨ç½²

### åœºæ™¯ 2: CI/CD é›†æˆ

```yaml
# .github/workflows/benchmark.yml
- name: Run benchmark
  run: |
    pip install numpy pandas aiohttp tqdm
    python test_with_jsonl.py \
      --model $MODEL_NAME \
      --num-prompts 20 \
      --save-result
```

### åœºæ™¯ 3: å…¬æœ‰äº‘ API æµ‹è¯•

```bash
# æµ‹è¯• OpenAI/Azure/å…¶ä»–å…¬æœ‰äº‘
export OPENAI_API_KEY="sk-..."
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 50 \
    --request-rate 5
```

### åœºæ™¯ 4: æ€§èƒ½å‹æµ‹

```bash
# æœ€å¤§ååé‡æµ‹è¯•
python test_with_jsonl.py \
    --model your-model \
    --num-prompts 1000 \
    --request-rate inf \
    --max-concurrency 100 \
    --save-result
```

---

## âš ï¸ å·²çŸ¥é™åˆ¶ä¸æƒè¡¡

### 1. Token ç»Ÿè®¡ç²¾åº¦

| æ–¹é¢ | æ”¹é€ å‰ | æ”¹é€ å | å½±å“ |
|------|--------|--------|------|
| Input tokens | Â±1% | Â±10-20% | ä»…ç»Ÿè®¡ï¼Œä¸å½±å“ API |
| Output tokens | Â±1% | ç²¾ç¡®ï¼ˆAPIè¿”å›ï¼‰ | æ— å½±å“ |
| ååé‡æµ‹è¯• | ç²¾ç¡® | ç²¾ç¡® | æ— å½±å“ |
| å»¶è¿Ÿæµ‹è¯• | ç²¾ç¡® | ç²¾ç¡® | æ— å½±å“ |

**ç»“è®º**ï¼š
- âœ… æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ï¼ˆå»¶è¿Ÿã€ååé‡ï¼‰**ä¸å—å½±å“**
- âš ï¸ Input token ç»Ÿè®¡æœ‰è¯¯å·®ï¼Œä½†ä¸å½±å“ç›¸å¯¹æ¯”è¾ƒ
- âœ… ç”¨æˆ·**æ˜ç¡®çŸ¥æ‚‰**æ­¤æƒè¡¡

### 2. æ•°æ®é›†é™åˆ¶

**å½±å“**ï¼š
- âŒ æ— æ³•ä½¿ç”¨ HuggingFace é¢„åˆ¶æ•°æ®é›†
- âŒ æ— æ³•åœ¨çº¿ä¸‹è½½å…¬å¼€æ•°æ®é›†

**è§£å†³æ–¹æ¡ˆ**ï¼š
- âœ… ä½¿ç”¨ `custom` æ•°æ®é›†
- âœ… å‡†å¤‡æœ¬åœ° JSONL æ–‡ä»¶
- âœ… é¡¹ç›®æä¾› 100 æ¡ç¤ºä¾‹æ•°æ®

### 3. å¤šæ¨¡æ€æ”¯æŒ

**å½±å“**ï¼š
- âŒ å›¾åƒã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€åŠŸèƒ½ç¦ç”¨

**åŸå› **ï¼š
- Pillowã€soundfile ç­‰åº“ä¸æ˜¯æ ¸å¿ƒä¾èµ–
- å¤šæ¨¡æ€æµ‹è¯•åœºæ™¯è¾ƒå°‘

**å¦‚éœ€ä½¿ç”¨**ï¼š
- æ‰‹åŠ¨å®‰è£…ï¼š`pip install Pillow soundfile`

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### å®‰è£…é€Ÿåº¦

```
æ”¹é€ å‰ï¼š~5 åˆ†é’Ÿï¼ˆä¸‹è½½ transformers + ä¾èµ–ï¼‰
æ”¹é€ åï¼š~30 ç§’ï¼ˆä»… 4 ä¸ªæ ¸å¿ƒä¾èµ–ï¼‰
```

### å†…å­˜å ç”¨

```
æ”¹é€ å‰ï¼š~1GBï¼ˆtransformers + æ¨¡å‹è¯è¡¨ï¼‰
æ”¹é€ åï¼š~100MBï¼ˆä»…æ ¸å¿ƒåº“ï¼‰
```

### å¯åŠ¨é€Ÿåº¦

```
æ”¹é€ å‰ï¼š~5 ç§’ï¼ˆåŠ è½½ tokenizerï¼‰
æ”¹é€ åï¼š~1 ç§’ï¼ˆæ— é¢å¤–åŠ è½½ï¼‰
```

### æµ‹è¯•ç²¾åº¦

| æŒ‡æ ‡ | æ”¹é€ å‰ | æ”¹é€ å |
|------|--------|--------|
| TTFT | ç²¾ç¡® | ç²¾ç¡® |
| TPOT | ç²¾ç¡® | ç²¾ç¡® |
| ITL | ç²¾ç¡® | ç²¾ç¡® |
| E2EL | ç²¾ç¡® | ç²¾ç¡® |
| ååé‡ | ç²¾ç¡® | ç²¾ç¡® |
| Input tokens | Â±1% | Â±10-20% |
| Output tokens | Â±1% | ç²¾ç¡® |

**ç»“è®º**ï¼šæ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡å®Œå…¨ä¸å—å½±å“ï¼

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: æ‰¾ä¸åˆ° transformers

**ä¸åº”è¯¥å‘ç”Ÿ** - å·²å®Œå…¨ç§»é™¤ã€‚å¦‚é‡åˆ°ï¼š
```bash
find . -type d -name __pycache__ -exec rm -rf {} +
```

### é—®é¢˜ 2: æ•°æ®é›†ä¸æ”¯æŒ

```
ValueError: Unsupported dataset: sharegpt
```

**è§£å†³**ï¼š
```bash
# æ”¹ç”¨ custom
--dataset-name custom --dataset-path your_data.jsonl
```

### é—®é¢˜ 3: Token ç»Ÿè®¡ä¸å‡†

**è¿™æ˜¯é¢„æœŸè¡Œä¸º**ï¼š
- Input token ä½¿ç”¨å­—ç¬¦ä¼°ç®—ï¼ˆÂ±10-20%ï¼‰
- ä¸å½±å“ API è°ƒç”¨å’Œæ€§èƒ½æµ‹è¯•
- ç”¨æˆ·å·²çŸ¥æ‚‰æ­¤æƒè¡¡

### é—®é¢˜ 4: JSONL æ ¼å¼é”™è¯¯

```bash
# ä½¿ç”¨æ£€æŸ¥å·¥å…·
python inspect_jsonl.py your_data.jsonl
```

---

## ğŸ“š æ–‡æ¡£ç´¢å¼•

| æ–‡æ¡£ | ç”¨é€” |
|------|------|
| [README.md](README.md) | é¡¹ç›®æ€»è§ˆ |
| [JSONL_TESTING_GUIDE.md](JSONL_TESTING_GUIDE.md) | JSONL æµ‹è¯•å®Œæ•´æŒ‡å— |
| [TOKENIZER_REMOVED.md](TOKENIZER_REMOVED.md) | Tokenizer ç§»é™¤è¯´æ˜ |
| [VLLM_DEPENDENCY_REMOVAL.md](VLLM_DEPENDENCY_REMOVAL.md) | vLLM ç§»é™¤è¯´æ˜ |
| [XLSXWRITER_OPTIONAL.md](XLSXWRITER_OPTIONAL.md) | Excel å¯¼å‡ºè¯´æ˜ |
| [OFFLINE_MODE_SUMMARY.md](OFFLINE_MODE_SUMMARY.md) | æ”¹é€ æ€»ç»“ï¼ˆæœ¬æ–‡ï¼‰ |
| [requirements.txt](requirements.txt) | ä¾èµ–åˆ—è¡¨ |

---

## âœ… éªŒæ”¶æ£€æŸ¥

### åŠŸèƒ½éªŒæ”¶

- [x] ä»…éœ€ 4 ä¸ªæ ¸å¿ƒä¾èµ–å³å¯è¿è¡Œ
- [x] æ”¯æŒç¦»çº¿/å†…ç½‘ç¯å¢ƒ
- [x] Custom æ•°æ®é›†å®Œå…¨å¯ç”¨
- [x] æ‰€æœ‰æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡ç²¾ç¡®
- [x] Token ç»Ÿè®¡ä½¿ç”¨ API å“åº” + å­—ç¬¦ä¼°ç®—
- [x] ç§»é™¤æ‰€æœ‰éœ€è¦å¤–éƒ¨ä¸‹è½½çš„ä¾èµ–
- [x] æä¾›å®Œæ•´æ–‡æ¡£å’Œç¤ºä¾‹
- [x] ä»£ç å¯æ­£å¸¸ç¼–è¯‘ï¼Œæ— è¯­æ³•é”™è¯¯

### æ€§èƒ½éªŒæ”¶

- [x] å¯åŠ¨æ—¶é—´ < 2s
- [x] å†…å­˜å ç”¨ < 200MB
- [x] å®‰è£…æ—¶é—´ < 1 åˆ†é’Ÿ
- [x] TTFT/TPOT/ååé‡ç­‰æ ¸å¿ƒæŒ‡æ ‡ç²¾ç¡®

### æ–‡æ¡£éªŒæ”¶

- [x] æä¾› JSONL æµ‹è¯•æŒ‡å—
- [x] æä¾›ä¾èµ–ç§»é™¤è¯´æ˜
- [x] æä¾›å¿«é€Ÿå¼€å§‹æŒ‡å—
- [x] æä¾›ç¤ºä¾‹æ•°æ®ï¼ˆ100æ¡ï¼‰
- [x] æä¾›ä¾¿æ·æµ‹è¯•è„šæœ¬

---

## ğŸ‰ æ€»ç»“

### æ ¸å¿ƒæˆæœ

1. âœ… **ä¾èµ–ç²¾ç®€**ï¼š10+ ä¸ªä¾èµ– â†’ 4 ä¸ªæ ¸å¿ƒä¾èµ–
2. âœ… **ç¦»çº¿æ”¯æŒ**ï¼šå®Œå…¨æ”¯æŒå†…ç½‘/ç¦»çº¿ç¯å¢ƒ
3. âœ… **æ€§èƒ½ä¸å˜**ï¼šæ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡å®Œå…¨ç²¾ç¡®
4. âœ… **æ˜“äºä½¿ç”¨**ï¼šæä¾›ä¾¿æ·è„šæœ¬å’Œå®Œæ•´æ–‡æ¡£
5. âœ… **å¿«é€Ÿéƒ¨ç½²**ï¼šå®‰è£…æ—¶é—´ä» 5 åˆ†é’Ÿå‡å°‘åˆ° 30 ç§’

### æƒè¡¡è¯´æ˜

1. âš ï¸ Input token ç»Ÿè®¡ä½¿ç”¨å­—ç¬¦ä¼°ç®—ï¼ˆÂ±10-20% è¯¯å·®ï¼‰
2. âš ï¸ éƒ¨åˆ†æ•°æ®é›†ä¸å¯ç”¨ï¼ˆHFã€ShareGPT ç­‰ï¼‰
3. âš ï¸ å¤šæ¨¡æ€åŠŸèƒ½é»˜è®¤ç¦ç”¨

### é€‚ç”¨åœºæ™¯

âœ… **æ¨èä½¿ç”¨**ï¼š
- å†…ç½‘/ç¦»çº¿ç¯å¢ƒæµ‹è¯•
- CI/CD é›†æˆ
- å¿«é€Ÿæ€§èƒ½è¯„ä¼°
- è¿œç«¯ API æµ‹è¯•

âŒ **ä¸æ¨èä½¿ç”¨**ï¼š
- éœ€è¦ç²¾ç¡® Input token ç»Ÿè®¡çš„åœºæ™¯
- éœ€è¦ä½¿ç”¨å…¬å¼€æ•°æ®é›†ï¼ˆå¦‚ ShareGPTï¼‰
- å¤šæ¨¡æ€æµ‹è¯•åœºæ™¯

---

**æ”¹é€ å®Œæˆæ—¶é—´**ï¼š2025-10-28
**æ”¹é€ ç›®æ ‡**ï¼šâœ… å…¨éƒ¨è¾¾æˆ
