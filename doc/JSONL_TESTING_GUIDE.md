# ä½¿ç”¨ online_query_etl_100.jsonl æµ‹è¯•å¤§æ¨¡å‹ API

## ğŸ“‹ æ•°æ®é›†ä¿¡æ¯

**æ–‡ä»¶**: `online_query_etl_100.jsonl`
- **æ ¼å¼**: JSONL (JSON Lines)
- **å¯¹è¯æ•°**: 100 æ¡
- **å†…å®¹**: ä¸­æ–‡å¯¹è¯ï¼Œæ¶µç›–è®¡ç®—æœºçŸ¥è¯†é—®ç­”ç­‰å¤šè½®å¯¹è¯

### æ•°æ®æ ¼å¼
æ¯è¡Œæ˜¯ä¸€ä¸ª JSON æ•°ç»„ï¼ŒåŒ…å«å¤šè½®å¯¹è¯ï¼š
```json
[
  {"role": "user", "content": "ç¬¬äºŒä»£è®¡ç®—æœºé‡‡ç”¨ä»€ä¹ˆä½œä¸ºé€»è¾‘å…ƒä»¶"},
  {"role": "assistant", "content": "ç¬¬äºŒä»£è®¡ç®—æœºé‡‡ç”¨çš„é€»è¾‘å…ƒä»¶æ˜¯**æ™¶ä½“ç®¡**..."}
]
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ä½¿ç”¨ Python è„šæœ¬ï¼ˆæ¨èï¼‰

#### åŸºç¡€æµ‹è¯•ï¼ˆ10æ¡æ•°æ®ï¼‰
```bash
python test_with_jsonl.py --model gpt-4
```

#### æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹
```bash
python test_with_jsonl.py --help
```

#### å®Œæ•´ç¤ºä¾‹
```bash
# æµ‹è¯• 50 æ¡æ•°æ®ï¼Œè¯·æ±‚é€Ÿç‡ 5 RPSï¼Œä¿å­˜ç»“æœ
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 50 \
    --request-rate 5 \
    --save-result
```

### æ–¹æ³• 2: ä½¿ç”¨ Shell è„šæœ¬
```bash
./test_with_jsonl.sh
```
è„šæœ¬ä¼šäº¤äº’å¼åœ°è¯¢é—®ä½ æµ‹è¯•å‚æ•°ã€‚

### æ–¹æ³• 3: ç›´æ¥ä½¿ç”¨ benchmark_serving.py
```bash
python benchmark_serving.py \
    --backend openai-chat \
    --model gpt-4 \
    --base-url https://api.openai.com \
    --dataset-name custom \
    --dataset-path online_query_etl_100.jsonl \
    --num-prompts 10 \
    --request-rate 1
```

---

## ğŸ”§ é…ç½®é€‰é¡¹

### å¿…éœ€å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--model` | æ¨¡å‹åç§° | `gpt-4`, `gpt-3.5-turbo` |

### API é…ç½®

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--base-url` | API åŸºç¡€ URL | `https://api.openai.com` |
| `--backend` | åç«¯ç±»å‹ | `openai-chat` |

**æ”¯æŒçš„åç«¯ç±»å‹**:
- `openai-chat`: OpenAI Chat Completions API
- `openai`: OpenAI Completions API
- `vllm`: vLLM OpenAI å…¼å®¹æœåŠ¡å™¨
- `tgi`: HuggingFace TGI
- `lmdeploy`: LMDeploy
- `sglang`: SGLang
- `tensorrt-llm`: TensorRT-LLM

### æµ‹è¯•å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--num-prompts` | æµ‹è¯•çš„å¯¹è¯æ•°é‡ | 10 |
| `--request-rate` | è¯·æ±‚é€Ÿç‡ (RPS) | 1.0 |
| `--max-concurrency` | æœ€å¤§å¹¶å‘æ•° | æ— é™åˆ¶ |

### è¾“å‡ºé€‰é¡¹

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--save-result` | ä¿å­˜æµ‹è¯•ç»“æœ | ä¸ä¿å­˜ |
| `--result-dir` | ç»“æœä¿å­˜ç›®å½• | `./results` |
| `--disable-tqdm` | ç¦ç”¨è¿›åº¦æ¡ | æ˜¾ç¤ºè¿›åº¦æ¡ |

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æµ‹è¯• OpenAI API
```bash
# è®¾ç½® API Key
export OPENAI_API_KEY="sk-..."

# è¿è¡Œæµ‹è¯•
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 20 \
    --request-rate 2 \
    --save-result
```

### ç¤ºä¾‹ 2: æµ‹è¯•æœ¬åœ° vLLM æœåŠ¡å™¨
```bash
# å‡è®¾ vLLM æœåŠ¡å™¨è¿è¡Œåœ¨ http://localhost:8000
python test_with_jsonl.py \
    --model Qwen/Qwen2.5-7B-Instruct \
    --base-url http://localhost:8000 \
    --backend vllm \
    --num-prompts 100 \
    --request-rate 10
```

### ç¤ºä¾‹ 3: æ€§èƒ½å‹æµ‹ï¼ˆæœ€å¤§ååé‡ï¼‰
```bash
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 100 \
    --request-rate inf \
    --max-concurrency 50 \
    --save-result
```

### ç¤ºä¾‹ 4: ç¨³å®šæ€§æµ‹è¯•ï¼ˆå›ºå®šé€Ÿç‡ï¼‰
```bash
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 100 \
    --request-rate 5 \
    --save-result \
    --result-dir ./stability_test
```

### ç¤ºä¾‹ 5: æµ‹è¯•è‡ªå®šä¹‰ API
```bash
python test_with_jsonl.py \
    --model your-model-name \
    --base-url https://your-api.com \
    --backend openai-chat \
    --num-prompts 30 \
    --request-rate 3
```

---

## ğŸ“Š ç»“æœè§£è¯»

æµ‹è¯•å®Œæˆåä¼šæ˜¾ç¤ºä»¥ä¸‹æŒ‡æ ‡ï¼š

### æ ¸å¿ƒæŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | å•ä½ |
|------|------|------|
| **TTFT** | Time to First Token (é¦– token æ—¶é—´) | æ¯«ç§’ |
| **TPOT** | Time per Output Token (æ¯ token æ—¶é—´) | æ¯«ç§’ |
| **ITL** | Inter-token Latency (token é—´å»¶è¿Ÿ) | æ¯«ç§’ |
| **E2EL** | End-to-end Latency (ç«¯åˆ°ç«¯å»¶è¿Ÿ) | æ¯«ç§’ |
| **Throughput** | ååé‡ | tokens/s æˆ– requests/s |

### ç¤ºä¾‹è¾“å‡º
```
Successful requests:                     100
Benchmark duration (s):                  50.23
Total input tokens:                      15230
Total generated tokens:                  45680
Request throughput (req/s):              1.99
Input token throughput (tok/s):          303.15
Output token throughput (tok/s):         909.45
---------------Time to First Token----------------
Mean TTFT (ms):                          234.56
Median TTFT (ms):                        198.23
P99 TTFT (ms):                           567.89
```

---

## ğŸ” å¸¸è§é—®é¢˜

### é—®é¢˜ 1: API Key æœªè®¾ç½®
```
âš ï¸  è­¦å‘Š: OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
export OPENAI_API_KEY="your-api-key"
```

### é—®é¢˜ 2: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶
```
âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ 'online_query_etl_100.jsonl'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿æ–‡ä»¶åœ¨å½“å‰ç›®å½•
ls online_query_etl_100.jsonl

# æˆ–æŒ‡å®šå®Œæ•´è·¯å¾„
python test_with_jsonl.py \
    --dataset-path /path/to/online_query_etl_100.jsonl
```

### é—®é¢˜ 3: è¿æ¥è¶…æ—¶
```
ConnectionError: Connection timeout
```

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥ API åœ°å€æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. é™ä½è¯·æ±‚é€Ÿç‡: `--request-rate 0.5`

### é—®é¢˜ 4: é€Ÿç‡é™åˆ¶
```
Rate limit exceeded
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é™ä½è¯·æ±‚é€Ÿç‡
python test_with_jsonl.py \
    --model gpt-4 \
    --request-rate 0.5  # æ¯ç§’ 0.5 ä¸ªè¯·æ±‚
```

---

## ğŸ“ˆ é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰æ•°æ®å­é›†
æµ‹è¯•å‰ 20 æ¡å¯¹è¯ï¼š
```bash
head -20 online_query_etl_100.jsonl > test_subset.jsonl

python test_with_jsonl.py \
    --dataset-path test_subset.jsonl \
    --num-prompts 20
```

### 2. æ‰¹é‡æµ‹è¯•ä¸åŒé…ç½®
```bash
#!/bin/bash
# æµ‹è¯•ä¸åŒçš„è¯·æ±‚é€Ÿç‡
for rate in 1 5 10 20; do
    echo "Testing with rate: $rate RPS"
    python test_with_jsonl.py \
        --model gpt-4 \
        --num-prompts 50 \
        --request-rate $rate \
        --save-result \
        --result-dir "./results/rate_${rate}" \
        --disable-tqdm
done
```

### 3. å¯¹æ¯”å¤šä¸ªæ¨¡å‹
```bash
#!/bin/bash
# å¯¹æ¯”ä¸åŒæ¨¡å‹çš„æ€§èƒ½
for model in "gpt-3.5-turbo" "gpt-4" "gpt-4-turbo"; do
    echo "Testing model: $model"
    python test_with_jsonl.py \
        --model $model \
        --num-prompts 20 \
        --save-result \
        --result-dir "./results/${model}"
done
```

### 4. æŸ¥çœ‹æ•°æ®ç»Ÿè®¡
```bash
# ç»Ÿè®¡å¯¹è¯è½®æ•°åˆ†å¸ƒ
python3 << 'EOF'
import json

turns_dist = {}
with open('online_query_etl_100.jsonl', 'r') as f:
    for line in f:
        messages = json.loads(line)
        turns = len(messages)
        turns_dist[turns] = turns_dist.get(turns, 0) + 1

print("å¯¹è¯è½®æ•°åˆ†å¸ƒ:")
for turns in sorted(turns_dist.keys()):
    print(f"  {turns} è½®: {turns_dist[turns]} æ¡å¯¹è¯")
EOF
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å¼€å‘æµ‹è¯•
```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆå°‘é‡æ•°æ®ï¼‰
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 5 \
    --request-rate 1
```

### 2. åŠŸèƒ½éªŒè¯
```bash
# ä¸­ç­‰è§„æ¨¡æµ‹è¯•
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 30 \
    --request-rate 2 \
    --save-result
```

### 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
```bash
# å®Œæ•´æµ‹è¯•ï¼Œæ‰€æœ‰æ•°æ®
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 100 \
    --request-rate 5 \
    --save-result \
    --result-dir ./benchmark_results
```

### 4. å‹åŠ›æµ‹è¯•
```bash
# æœ€å¤§ååé‡æµ‹è¯•
python test_with_jsonl.py \
    --model gpt-4 \
    --num-prompts 100 \
    --request-rate inf \
    --max-concurrency 100 \
    --save-result
```

---

## ğŸ“ ç»“æœæ–‡ä»¶

å¦‚æœä½¿ç”¨ `--save-result`ï¼Œä¼šç”Ÿæˆ JSON æ ¼å¼çš„ç»“æœæ–‡ä»¶ï¼š

```json
{
  "duration": 50.23,
  "completed": 100,
  "total_input": 15230,
  "total_output": 45680,
  "request_throughput": 1.99,
  "input_throughput": 303.15,
  "output_throughput": 909.45,
  "mean_ttft_ms": 234.56,
  "median_ttft_ms": 198.23,
  "p99_ttft_ms": 567.89,
  ...
}
```

æŸ¥çœ‹ç»“æœï¼š
```bash
# æŸ¥çœ‹æœ€æ–°ç»“æœ
cat results/*.json | jq .

# æå–å…³é”®æŒ‡æ ‡
cat results/*.json | jq '{
  throughput: .request_throughput,
  ttft_ms: .mean_ttft_ms,
  tpot_ms: .mean_tpot_ms
}'
```

---

## ğŸ¤ è·å–å¸®åŠ©

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
- [README.md](README.md) - å®Œæ•´ä½¿ç”¨æŒ‡å—
- [VLLM_DEPENDENCY_REMOVAL.md](VLLM_DEPENDENCY_REMOVAL.md) - ä¾èµ–è¯´æ˜
- è¿è¡Œ `python test_with_jsonl.py --help` æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹

---

**ç¥æµ‹è¯•é¡ºåˆ©ï¼** ğŸ‰
